# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# DO AI Inference Configuration - Primary Endpoint
MODEL_ACCESS_KEY=your_do_ai_access_key_here
MODEL_BASE_URL=https://inference.do-ai.run/v1
MODEL_CHAT=anthropic-claude-opus-4
MODEL_IMAGE=stability-image-1
MAX_TOKENS=400

# DO AI Inference Configuration - Secondary Endpoint (Failover)
# Optional: Uncomment to enable multi-endpoint failover
# MODEL_ACCESS_KEY_2=your_secondary_access_key_here
# MODEL_BASE_URL_2=https://your-secondary-endpoint.agents.do-ai.run/api/v1
# MODEL_CHAT_2=llama3-8b-instruct
# MODEL_IMAGE_2=stability-image-1

# DO AI Inference Configuration - Third Endpoint (Optional)
# MODEL_ACCESS_KEY_3=your_third_access_key_here
# MODEL_BASE_URL_3=https://your-third-endpoint/v1
# MODEL_CHAT_3=anthropic-claude-opus-4
# MODEL_IMAGE_3=stability-image-1

# Rate Limiting
COOLDOWN=2

# Redis Configuration (Optional - will fallback to in-memory if not provided)
REDIS_URL=redis://:password@host:port/0
# Or use individual Redis settings:
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=your_password
# REDIS_USERNAME=default

# Webhook Configuration (Optional - for webhook mode instead of polling)
# WEBHOOK_URL=https://yourdomain.com/webhook
# PORT=8443

